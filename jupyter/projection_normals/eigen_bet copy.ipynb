{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserscan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flaten_3x3(m):\n",
    "     m = np.pad(m, [(1, 1), (1, 1)], mode='constant')\n",
    "     arr = np.array([np.matrix([m[i][j:j+3], m[i+1][j:j+3], m[i+2][j:j+3]]).flatten(\"C\") for j in range(len(m[0])-2) for i in range(len(m)-2)])\n",
    "     arr_s = np.squeeze(arr).reshape((len(m)-2, len(m[0])-2, 9))\n",
    "     return np.transpose(arr_s, axes=(1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700\n",
      "300\n",
      "points shape:  (64, 1024, 3)\n",
      "shape x :  (1024, 64, 9)\n",
      "torch.Size([1, 1024, 64, 3, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3ead883e20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x5760 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from laserscan import *\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "device = \"cuda:0\"\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CustomKitti(Dataset):\n",
    "    def __init__(self, dir, mode=\"train\"):\n",
    "        self.ls = SemLaserScan(project=True, nclasses=100)\n",
    "        self.mode = mode\n",
    "        self.len = 4541\n",
    "        self.train_len = 3700\n",
    "        self.val_len = 300\n",
    "        self.test_len = self.len - self.train_len - self.val_len\n",
    "        self.label_folder = dir + \"plane_labels/\"\n",
    "        self.file_folder = dir + \"velodyne/\"\n",
    "    def __len__(self):\n",
    "        if self.mode == \"train\":\n",
    "            return self.train_len\n",
    "        if self.mode == \"val\":\n",
    "            return self.val_len\n",
    "        return self.test_len\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            idx += self.train_len + self.val_len\n",
    "        if self.mode == \"val\":\n",
    "            idx += self.train_len\n",
    "        self.ls.open_scan(self.file_folder + '{0:06d}.bin'.format(idx))\n",
    "        self.ls.open_label(self.label_folder + 'label-{0:06d}.npy'.format(idx))\n",
    "        self.ls.proj_sem_label[self.ls.proj_sem_label != 0] = 1\n",
    "        print(\"points shape: \", self.ls.proj_xyz.shape)\n",
    "        print(\"shape x : \", flaten_3x3(self.ls.proj_xyz[:,:, 0]).shape)\n",
    "        return np.stack((flaten_3x3(self.ls.proj_xyz[:,:, 0]),flaten_3x3(self.ls.proj_xyz[:,:, 1]), flaten_3x3(self.ls.proj_xyz[:,:, 2])), axis=2).squeeze(), self.ls.proj_sem_label\n",
    "\n",
    "training_data = CustomKitti(\"/home/polosatik/mnt/kitty/dataset/sequences/00/\") \n",
    "validation_data = CustomKitti(\"/home/polosatik/mnt/kitty/dataset/sequences/00/\", mode=\"val\") \n",
    "test_data = CustomKitti(\"/home/polosatik/mnt/kitty/dataset/sequences/00/\", mode=\"test\") \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "training_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "print(len(training_loader))\n",
    "print(len(validation_loader))\n",
    "\n",
    "vinputs, vlabels = next(iter(test_loader))\n",
    "print(vinputs.shape)\n",
    "plt.figure(figsize=(20,80))\n",
    "plt.imshow(vlabels[0], cmap=\"gray\")\n",
    "# validation_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert input.size() == target.size()\n",
    "    if input.dim() == 2 and reduce_batch_first:\n",
    "        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {input.shape})')\n",
    "\n",
    "    if input.dim() == 2 or reduce_batch_first:\n",
    "        inter = torch.dot(input.reshape(-1), target.reshape(-1))\n",
    "        sets_sum = torch.sum(input) + torch.sum(target)\n",
    "        if sets_sum.item() == 0:\n",
    "            sets_sum = 2 * inter\n",
    "\n",
    "        return (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "    else:\n",
    "        # compute and average metric for each batch element\n",
    "        dice = 0\n",
    "        for i in range(input.shape[0]):\n",
    "            dice += dice_coeff(input[i, ...], target[i, ...])\n",
    "        return dice / input.shape[0]\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    assert input.size() == target.size()\n",
    "    dice = 0\n",
    "    for channel in range(input.shape[1]):\n",
    "        dice += dice_coeff(input[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)\n",
    "\n",
    "    return dice / input.shape[1]\n",
    "\n",
    "\n",
    "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    assert input.size() == target.size()\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(input, target, reduce_batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch-vectorized\n",
    "import torch\n",
    "from torchvectorized.utils import sym\n",
    "from torchvectorized.vlinalg import vSymEig\n",
    "from torchvectorized.nn import EigVals\n",
    "\n",
    "# Random batch of volumetric 3x3 symmetric matrices of size 16x9x32x32x32\n",
    "input = sym(torch.rand(4, 9, 3, 1024, 64))\n",
    "\n",
    "# Output eig_vals with size: 16x3x32x32x32 and eig_vecs with size 16,3,3,32,32,32\n",
    "eig_vals, eig_vecs = vSymEig(input, eigenvectors=True)\n",
    "# eig_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3890,  0.6894,  0.1773],\n",
      "         [-1.3035, -0.4007,  1.7280],\n",
      "         [ 0.5876, -0.8992,  0.8766]],\n",
      "\n",
      "        [[-0.2414,  0.6463,  0.7104],\n",
      "         [-0.4236, -0.3273, -0.4881],\n",
      "         [-0.2404,  2.9522, -1.8731]],\n",
      "\n",
      "        [[-2.1397, -0.6745, -0.3876],\n",
      "         [-0.0724,  0.7715, -0.5809],\n",
      "         [-0.5462,  1.9516, -0.2681]],\n",
      "\n",
      "        [[ 0.4998,  0.8560,  1.3809],\n",
      "         [-1.0624,  0.9621,  0.4652],\n",
      "         [ 0.4270, -0.4240,  0.4154]]])\n",
      "tensor([[ 0.5876, -0.8992,  0.8766],\n",
      "        [-0.2404,  2.9522, -1.8731],\n",
      "        [-0.5462,  1.9516, -0.2681],\n",
      "        [ 0.4270, -0.4240,  0.4154]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((4, 3, 3))\n",
    "print(a)\n",
    "print(a[:,2,:])\n",
    "#  * torch.randn((5, 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 2, 5]) torch.Size([1, 3, 3, 4, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvectorized.utils import sym\n",
    "from torchvectorized.vlinalg import vSymEig\n",
    "\n",
    "b, c, d, h, w = 1, 9, 4, 2, 5\n",
    "inputs = sym(torch.rand(b, c, d, h, w))\n",
    "v, u = vSymEig(inputs, eigenvectors=True)\n",
    "print(v.shape, u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvectorized.vlinalg import vSymEig\n",
    "\n",
    "\n",
    "def _grad_sym(X):\n",
    "    return 0.5 * (X + X.transpose(1, 2))\n",
    "\n",
    "\n",
    "class EigValsFunc(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, X):\n",
    "        # [4, 1024, 64, 3, 9]\n",
    "        new_x = torch.permute(X, (0, 4, 3, 2, 1))\n",
    "        print(\"X: \", new_x.shape)\n",
    "        # eigen values, eigen vectors\n",
    "        V, U = vSymEig(new_x, eigenvectors=True, flatten_output=False) \n",
    "        b, _, d, h, w = new_x.size()\n",
    "        eig_vals = V.permute(0, 2, 3, 4, 1).reshape(b * d * h * w, 3)\n",
    "        eig_vecs = U.permute(0, 3, 4, 5, 1, 2).reshape(b * d * h * w, 3, 3)\n",
    "        print(eig_vals.shape)\n",
    "        ctx.save_for_backward(eig_vals.float(), eig_vecs.float(), new_x)\n",
    "        # eigen values are in incresing order TODO: proper checkup\n",
    "        print(\"V: \", V.shape, \"U: \", U.shape) \n",
    "        # print(torch.argmax(V, dim=1), torch.argmax(V, dim=1).shape, torch.max(torch.argmax(V, dim=1)), torch.min(torch.argmax(V, dim=1)))\n",
    "        print(U[:,2,:].shape)\n",
    "        return U[:,2,:]\n",
    "\n",
    "    # @staticmethod\n",
    "    # def backward(ctx, *grad_outputs):\n",
    "    #     S, U, X = ctx.saved_tensors\n",
    "    #     b, c, d, h, w = X.size()\n",
    "\n",
    "    #     grad_X = torch.diag_embed(grad_outputs[0])\n",
    "\n",
    "    #     return _grad_sym(torch.bmm(torch.bmm(U, grad_X), U.transpose(1, 2))).reshape(b, d * h * w, 3, 3) \\\n",
    "    #                .permute(0, 2, 3, 1).reshape(b, c, d, h, w), None\n",
    "\n",
    "\n",
    "class EigVals(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Differentiable neural network layer (:class:`torch.nn.Module`) that performs eigendecomposition on\n",
    "    every voxel in a volume of flattened 3x3 symmetric matrices of shape **Bx9xDxHxW** and return the eigenvalues.\n",
    "\n",
    "    See **Ionescu et al., Matrix backpropagation for deep networks with structured layers, CVPR 2015** for details on the\n",
    "    gradients computation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "                                                                    ([1, 9, 3, 64, 1024])\n",
    "        Takes a volume of flattened 3x3 symmetric matrices of shape **Bx9xDxHxW** and return a volume of their eigenvalues\n",
    "\n",
    "        :param x: A volume of flattened 3x3 symmetric matrices of shape **Bx9xDxHxW**\n",
    "        :type x: torch.Tensor\n",
    "        :return: A tensor with shape **(B*D*H*W)x3** where every voxel's channels are the eigenvalues of the inpur matrix\n",
    "                                    ([1, 3, 64, 3, 9])\n",
    "            at the same spatial location.\n",
    "        :rtype: torch.Tensor\n",
    "        \"\"\"\n",
    "        return EigValsFunc.apply(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_classes = 2\n",
    "from unet import UNet\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# import torchvectorized\n",
    "def get_model_and_optimizer(device, num_encoding_blocks=5, out_channels_first_layer=8, patience=3):\n",
    "    #Better to train with num_encoding_blocks >=3, out_channels_first_layer>=4 '''\n",
    "    #repoducibility\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "      \n",
    "    # unet = UNet(\n",
    "    #       in_channels=5,\n",
    "    #       out_classes=max_classes,\n",
    "    #       dimensions=2,\n",
    "    #       num_encoding_blocks=num_encoding_blocks,\n",
    "    #       normalization='batch',\n",
    "    #       upsampling_type='linear',\n",
    "    #       padding=True,\n",
    "    #       activation='ReLU',\n",
    "    #   ).to(device)\n",
    "    # print( \"unet par:\", unet.parameters())\n",
    "    # model = unet\n",
    "    EV = EigVals()\n",
    "    # print(\"par: \", list(EV.parameters()))\n",
    "    model = nn.Sequential(nn.Linear(in_features=9, out_features=9, bias=False), EV)\n",
    "    model.to(device=device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience, threshold=0.01)\n",
    "    \n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "def train_one_epoch(epoch_index, tb_writer, optimizer, model):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = torch.tensor(inputs).permute(0, 1, 2, 4, 3).to(device=device, dtype=torch.float)\n",
    "        print(inputs.shape)\n",
    "        labels = torch.tensor(labels).to(device=device, dtype=torch.long)\n",
    "        # print(torch.max(labels))\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        print(outputs.shape, labels.shape)\n",
    "        # Compute the loss and its gradients\n",
    "        # loss = torch.nn.functional.mse_loss(outputs.squeeze(), labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 100== 99:\n",
    "            last_loss = running_loss / 100 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            # tb_writer.add_image(\"label\", visualize_seg(labels.numpy(), mc).squeeze()[0], 0)\n",
    "            # tb_writer.add_image(\"label\", visualize_seg(outputs.cpu().numpy(), mc).squeeze()[0], 0)\n",
    "\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# run_name = \"SEMANTIC_log softmax_nll_\"\n",
    "run_name = \"SEMANTIC_cross_entropy_dice_softmax_5 s\"\n",
    "writer = SummaryWriter('runs/{}_{}'.format(run_name, timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 40\n",
    "\n",
    "best_vloss = 1_000_00000.\n",
    "model, optimizer, scheduler = get_model_and_optimizer(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "points shape:  (64, 1024, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26328/1305379453.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs).permute(0, 1, 2, 4, 3).to(device=device, dtype=torch.float)\n",
      "/tmp/ipykernel_26328/1305379453.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).to(device=device, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 64, 3, 9])\n",
      "X:  torch.Size([1, 9, 3, 64, 1024])\n",
      "torch.Size([196608, 3])\n",
      "V:  torch.Size([1, 3, 3, 64, 1024]) U:  torch.Size([1, 3, 3, 3, 64, 1024])\n",
      "torch.Size([1, 3, 3, 64, 1024])\n",
      "torch.Size([1, 3, 3, 64, 1024]) torch.Size([1, 64, 1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [1, 3, 64, 1024], got [1, 64, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m train_one_epoch(epoch_number, writer, optimizer, model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# We don't need gradients on to do reporting\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb Cell 13\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_index, tb_writer, optimizer, model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(outputs\u001b[39m.\u001b[39mshape, labels\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Compute the loss and its gradients\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# loss = torch.nn.functional.mse_loss(outputs.squeeze(), labels)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B31.135.65.84/home/polosatik/SqueezeSeg/src/eigen_bet.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Adjust learning weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:1120\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1120\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1121\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2824\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2823\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2824\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [1, 3, 64, 1024], got [1, 64, 1024]"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train :\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(epoch_number, writer, optimizer, model)\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # We don't need gradients on to do reporting\n",
    "            model.train(False)\n",
    "\n",
    "            running_vloss = 0.0\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                vinputs = torch.tensor(vinputs).permute(0, 1, 2, 4, 3).to(device=device, dtype=torch.float)\n",
    "                vlabels = torch.tensor(vlabels).to(device=device, dtype=torch.long)\n",
    "\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = 'chpt/model_{}_{}_{}'.format(run_name, timestamp, epoch_number)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196608\n",
      "192.0\n",
      "1728\n"
     ]
    }
   ],
   "source": [
    "print(64*1024*3)\n",
    "print(1728/9)\n",
    "print(64*3*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9061)\n",
      "torch.Size([64, 1024]) torch.Size([2, 64, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9218953322843892, 0.9256186629880894, 0.92189533192352, 0.9293721914617133)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchmetrics import JaccardIndex\n",
    "import metrics\n",
    "\n",
    "jaccard = JaccardIndex(num_classes=2)\n",
    "pred = F.softmax(voutputs, dim=1)[0].permute(1,2,0).detach().squeeze()[:,:, 1]\n",
    "vlabels.shape\n",
    "print(jaccard(pred.cpu(), vlabels[0].int().cpu()))\n",
    "metric_calculator = metrics.SegmentationMetrics(average=True, ignore_background=True, activation=\"softmax\")\n",
    "print(vlabels[0].int().shape, voutputs[0].shape)\n",
    "metric_calculator(vlabels.int(), voutputs)\n",
    "# pred\n",
    "# F.softmax(voutputs, dim=1)[0].cpu().permute(1,2,0).detach().numpy().squeeze()[:,:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14367/1610888461.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tinputs = torch.tensor(tinputs).permute(0,3,1,2).to(device=device, dtype=torch.float)\n",
      "/tmp/ipykernel_14367/1610888461.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tlabels = torch.tensor(tlabels).to(device=device, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference: 64.68943786621094, batch_iou: 0.8447953462600708, precision: 0.7793742083436951, recall: 0.8479480097156241, dice: 0.8122162917723272, acc: 0.7793742088654328\n",
      "inference: 59.759742736816406, batch_iou: 0.8830991983413696, precision: 0.847964815312653, recall: 0.8930762186791857, dice: 0.8699360853724435, acc: 0.8479648159053155\n",
      "inference: 58.6673583984375, batch_iou: 0.9214291572570801, precision: 0.9258089691020912, recall: 0.9449404892353417, dice: 0.935276903374103, acc: 0.9258089694196798\n",
      "inference: 56.51443099975586, batch_iou: 0.8905607461929321, precision: 0.904352996881189, recall: 0.9082917699426406, dice: 0.9063181040228906, acc: 0.9043529973648238\n",
      "inference: 56.59910583496094, batch_iou: 0.905887246131897, precision: 0.8841247129011479, recall: 0.927893137910955, dice: 0.905480322684691, acc: 0.8841247134371755\n",
      "inference: 56.567134857177734, batch_iou: 0.7872521281242371, precision: 0.553210848388902, recall: 0.8677899469837331, dice: 0.6756798649185617, acc: 0.5532108486285355\n",
      "inference: 56.63711929321289, batch_iou: 0.8604093790054321, precision: 0.8313475645053379, recall: 0.8343338625372185, dice: 0.8328380364862088, acc: 0.8313475650991954\n",
      "inference: 56.536705017089844, batch_iou: 0.8427658081054688, precision: 0.8640434757358865, recall: 0.7669203227739405, dice: 0.8125900793866195, acc: 0.8640434763151927\n",
      "inference: 56.66041564941406, batch_iou: 0.8879827857017517, precision: 0.8684469939276822, recall: 0.8862654198659136, dice: 0.8772657372403554, acc: 0.8684469945486138\n",
      "inference: 56.521793365478516, batch_iou: 0.8669235706329346, precision: 0.8106472924073891, recall: 0.8532580502141522, dice: 0.8314070642868573, acc: 0.8106472929800872\n",
      "inference: 56.8026237487793, batch_iou: 0.8340128660202026, precision: 0.6416510926425486, recall: 0.8924464414805342, dice: 0.746548666559705, acc: 0.6416510930106443\n",
      "inference: 56.73984146118164, batch_iou: 0.8115527033805847, precision: 0.8080828836193336, recall: 0.7441803580815185, dice: 0.774816272750449, acc: 0.8080828842007879\n",
      "inference: 56.79024124145508, batch_iou: 0.8755879998207092, precision: 0.8280499989948485, recall: 0.8970635655127894, dice: 0.8611763303664286, acc: 0.8280499996220299\n",
      "inference: 56.785377502441406, batch_iou: 0.800683856010437, precision: 0.6922248292225986, recall: 0.8588278220786533, dice: 0.7665786740838897, acc: 0.6922248294684852\n",
      "inference: 56.94617462158203, batch_iou: 0.8062745928764343, precision: 0.7423341685520108, recall: 0.7782121482021861, dice: 0.7598498796586219, acc: 0.742334169284665\n",
      "inference: 56.781822204589844, batch_iou: 0.8356263637542725, precision: 0.77407026474743, recall: 0.8277347144292249, dice: 0.8000035432296748, acc: 0.7740702655585965\n",
      "inference: 56.90969467163086, batch_iou: 0.8641153573989868, precision: 0.8699163913930877, recall: 0.892570821035518, dice: 0.8810980099042337, acc: 0.8699163917493367\n",
      "inference: 56.9317741394043, batch_iou: 0.8429806232452393, precision: 0.8681465605317767, recall: 0.8873852867878388, dice: 0.8776605058405188, acc: 0.868146560892103\n",
      "inference: 56.776798248291016, batch_iou: 0.8527064323425293, precision: 0.8756158548549194, recall: 0.8782593928132088, dice: 0.8769356315620024, acc: 0.8756158552615051\n",
      "inference: 56.830623626708984, batch_iou: 0.8586559891700745, precision: 0.8968171828886802, recall: 0.9029211987491926, dice: 0.8998588395671279, acc: 0.8968171832890371\n",
      "inference: 56.949951171875, batch_iou: 0.8930860161781311, precision: 0.8963273135312354, recall: 0.8743749199900425, dice: 0.8852150386361178, acc: 0.8963273139592756\n",
      "inference: 56.77833557128906, batch_iou: 0.8213704824447632, precision: 0.8486718470091147, recall: 0.6978000155556471, dice: 0.7658764990195623, acc: 0.8486718478186549\n",
      "inference: 57.00041580200195, batch_iou: 0.8873710632324219, precision: 0.9149921167935086, recall: 0.8629111192391715, dice: 0.888188800794578, acc: 0.9149921173050912\n",
      "inference: 56.855712890625, batch_iou: 0.8623924851417542, precision: 0.8872321199201628, recall: 0.811636120977896, dice: 0.8477521903449299, acc: 0.8872321207044025\n",
      "inference: 56.74854278564453, batch_iou: 0.8760720491409302, precision: 0.8793128889611087, recall: 0.8308228551248465, dice: 0.8543804168054059, acc: 0.8793128895680564\n",
      "inference: 56.762718200683594, batch_iou: 0.7739900350570679, precision: 0.6795238268317492, recall: 0.7177184694254201, dice: 0.6980991087479459, acc: 0.6795238272755387\n",
      "inference: 56.70275115966797, batch_iou: 0.8613432049751282, precision: 0.7922148389806112, recall: 0.9311582071576222, dice: 0.8560855129412582, acc: 0.7922148396031902\n",
      "inference: 56.748191833496094, batch_iou: 0.8187260627746582, precision: 0.7392026007572491, recall: 0.8233938296219679, dice: 0.7790301429194003, acc: 0.7392026012626332\n",
      "inference: 56.8421745300293, batch_iou: 0.8564853668212891, precision: 0.841267019245485, recall: 0.9581905795436751, dice: 0.895930121663255, acc: 0.841267019520358\n",
      "inference: 56.82166290283203, batch_iou: 0.8279561400413513, precision: 0.8582874082297557, recall: 0.8695607515400468, dice: 0.8638873033910102, acc: 0.8582874086836807\n",
      "inference: 56.789825439453125, batch_iou: 0.9123630523681641, precision: 0.9079896697478362, recall: 0.9234340661509717, dice: 0.9156467466338751, acc: 0.9079896701306851\n",
      "inference: 56.72380828857422, batch_iou: 0.8959693908691406, precision: 0.8416584489620083, recall: 0.9119282637365211, dice: 0.875385428524973, acc: 0.8416584496352064\n",
      "inference: 56.91958236694336, batch_iou: 0.8261114358901978, precision: 0.8084262914241513, recall: 0.8131428322858457, dice: 0.8107777024683331, acc: 0.80842629190109\n",
      "inference: 56.79926300048828, batch_iou: 0.8790826201438904, precision: 0.8716713062449399, recall: 0.9522645472494589, dice: 0.9101873623315089, acc: 0.8716713065448681\n",
      "inference: 56.75843048095703, batch_iou: 0.8837357759475708, precision: 0.8509558085161107, recall: 0.9009774131735495, dice: 0.8752524965613123, acc: 0.8509558090546108\n",
      "inference: 56.94438552856445, batch_iou: 0.8022012114524841, precision: 0.7536640249002942, recall: 0.7703237272736355, dice: 0.7619028169757598, acc: 0.7536640254287952\n",
      "inference: 56.80748748779297, batch_iou: 0.8406193256378174, precision: 0.726990653676113, recall: 0.8234473126170182, dice: 0.7722185769597268, acc: 0.7269906542162398\n",
      "inference: 56.79478454589844, batch_iou: 0.8957964181900024, precision: 0.9040406248854189, recall: 0.917908379351433, dice: 0.9109217249372994, acc: 0.9040406251688539\n",
      "inference: 56.8218879699707, batch_iou: 0.9230517148971558, precision: 0.9328796530977347, recall: 0.9384656665817778, dice: 0.9356643226313829, acc: 0.932879653446105\n",
      "inference: 56.863487243652344, batch_iou: 0.921891450881958, precision: 0.9227035078850443, recall: 0.9097930909508923, dice: 0.9162028207751727, acc: 0.9227035081941024\n",
      "inference: 56.87654495239258, batch_iou: 0.8227270841598511, precision: 0.7693088359020199, recall: 0.7738811726955943, dice: 0.7715882305181654, acc: 0.7693088363317107\n",
      "inference: 56.814273834228516, batch_iou: 0.8435490131378174, precision: 0.7712602830751756, recall: 0.8600878825157221, dice: 0.8132557324912425, acc: 0.7712602836578264\n",
      "inference: 56.77596664428711, batch_iou: 0.8349423408508301, precision: 0.7174449956952157, recall: 0.8589192436055137, dice: 0.7818336620099356, acc: 0.7174449964157558\n",
      "inference: 56.7716178894043, batch_iou: 0.8953830003738403, precision: 0.8832074033253798, recall: 0.8658011028039907, dice: 0.8744176384357121, acc: 0.883207403925742\n",
      "inference: 56.9510383605957, batch_iou: 0.9160639047622681, precision: 0.888237192818575, recall: 0.9337862433895329, dice: 0.9104423741344332, acc: 0.8882371933704071\n",
      "inference: 56.76502227783203, batch_iou: 0.915911078453064, precision: 0.8997811723445681, recall: 0.9278656097497333, dice: 0.913607612014624, acc: 0.8997811728189071\n",
      "inference: 56.83555221557617, batch_iou: 0.8793853521347046, precision: 0.872730067884264, recall: 0.8982435117498734, dice: 0.8853030106965386, acc: 0.8727300683756247\n",
      "inference: 56.89686584472656, batch_iou: 0.9141655564308167, precision: 0.934107633575129, recall: 0.9446112251429198, dice: 0.9393300674695894, acc: 0.9341076338603338\n",
      "inference: 56.7658576965332, batch_iou: 0.9173678159713745, precision: 0.912938791079543, recall: 0.9217509042109494, dice: 0.9173236850901477, acc: 0.9129387917126109\n",
      "inference: 56.88185501098633, batch_iou: 0.8698021173477173, precision: 0.8780218614269266, recall: 0.820690338788968, dice: 0.8483886308357546, acc: 0.8780218622173661\n",
      "inference: 56.80137634277344, batch_iou: 0.9166103601455688, precision: 0.9123033937548445, recall: 0.9174418131868742, dice: 0.9148653884166594, acc: 0.9123033941485917\n",
      "inference: 56.92502212524414, batch_iou: 0.8500760197639465, precision: 0.8117171866759939, recall: 0.9007750838876993, dice: 0.8539304141279943, acc: 0.811717186977467\n",
      "inference: 56.825984954833984, batch_iou: 0.8845674991607666, precision: 0.8998765552440612, recall: 0.918233931145602, dice: 0.9089625663964293, acc: 0.8998765556103386\n",
      "inference: 56.793888092041016, batch_iou: 0.8866233825683594, precision: 0.8648763422010671, recall: 0.8907399311594354, dice: 0.8776176265453121, acc: 0.86487634280591\n",
      "inference: 56.79724884033203, batch_iou: 0.8978995680809021, precision: 0.903387875342507, recall: 0.8892559989101787, dice: 0.8962662344699495, acc: 0.9033878759302395\n",
      "inference: 56.7762565612793, batch_iou: 0.8757016658782959, precision: 0.8789661375288943, recall: 0.9326015933033582, dice: 0.9049898674501883, acc: 0.8789661378797838\n",
      "inference: 56.735809326171875, batch_iou: 0.8854628801345825, precision: 0.8703672500600438, recall: 0.843292160162435, dice: 0.8566158176062797, acc: 0.8703672507015575\n",
      "inference: 56.756065368652344, batch_iou: 0.8479902148246765, precision: 0.8036307972487152, recall: 0.8164300468860636, dice: 0.8099798619150521, acc: 0.8036307979088438\n",
      "inference: 56.7724494934082, batch_iou: 0.9227694272994995, precision: 0.942661224602068, recall: 0.9383587605614118, dice: 0.9405050720473014, acc: 0.9426612250276786\n",
      "inference: 56.73817443847656, batch_iou: 0.8884381055831909, precision: 0.8437453422733238, recall: 0.8999956877651877, dice: 0.8709632410936728, acc: 0.8437453428948454\n",
      "inference: 56.8966064453125, batch_iou: 0.8949058055877686, precision: 0.9030868428984649, recall: 0.8890655516482512, dice: 0.8960213479439003, acc: 0.9030868434158823\n",
      "inference: 56.87846374511719, batch_iou: 0.9243721961975098, precision: 0.938066223246608, recall: 0.9250453984387432, dice: 0.9315103111719701, acc: 0.9380662236306183\n",
      "inference: 56.77040100097656, batch_iou: 0.8859092593193054, precision: 0.9106208576074073, recall: 0.9065666663053344, dice: 0.9085892394323608, acc: 0.9106208580541002\n",
      "inference: 56.81353759765625, batch_iou: 0.8837621212005615, precision: 0.8260583627519117, recall: 0.9098483021556698, dice: 0.8659311171494016, acc: 0.8260583631048956\n",
      "inference: 56.887168884277344, batch_iou: 0.9221113324165344, precision: 0.9102756319882713, recall: 0.9428452750819553, dice: 0.9262742386046317, acc: 0.9102756325902104\n",
      "inference: 56.835777282714844, batch_iou: 0.9150575399398804, precision: 0.9162826918541785, recall: 0.9161759037077225, dice: 0.9162292946442178, acc: 0.9162826924042983\n",
      "inference: 56.78799819946289, batch_iou: 0.8735504150390625, precision: 0.8611954618953834, recall: 0.8434810125130672, dice: 0.8522461957300319, acc: 0.861195462429317\n",
      "inference: 56.846431732177734, batch_iou: 0.8664289712905884, precision: 0.874883007896947, recall: 0.8828865784337425, dice: 0.8788665719958155, acc: 0.874883008281081\n",
      "inference: 56.84975814819336, batch_iou: 0.8459389805793762, precision: 0.8103954477448451, recall: 0.8242761716502969, dice: 0.8172768759355105, acc: 0.8103954482839536\n",
      "inference: 56.90339279174805, batch_iou: 0.9208001494407654, precision: 0.9251693943444886, recall: 0.9325250123918971, dice: 0.9288326409163772, acc: 0.9251693947188857\n",
      "inference: 56.842430114746094, batch_iou: 0.8934577703475952, precision: 0.9111911823376382, recall: 0.8688410332258383, dice: 0.8895123148636523, acc: 0.9111911829002225\n",
      "inference: 56.853759765625, batch_iou: 0.8664954900741577, precision: 0.8245149361970328, recall: 0.8639730799285357, dice: 0.8437829608718124, acc: 0.824514936829048\n",
      "inference: 56.835201263427734, batch_iou: 0.8750805854797363, precision: 0.8374022728785093, recall: 0.8772400829713406, dice: 0.8568583842380331, acc: 0.8374022735525174\n",
      "inference: 56.857505798339844, batch_iou: 0.9288417100906372, precision: 0.9403880865570727, recall: 0.9431111548188832, dice: 0.9417476522408811, acc: 0.9403880868691934\n",
      "inference: 56.78220748901367, batch_iou: 0.851606011390686, precision: 0.7547406211197897, recall: 0.8560056934584606, dice: 0.8021899697534233, acc: 0.7547406218056137\n",
      "inference: 56.93062210083008, batch_iou: 0.9218367338180542, precision: 0.9177553445257329, recall: 0.9334124212188876, dice: 0.9255176695032281, acc: 0.9177553449114396\n",
      "inference: 56.74028778076172, batch_iou: 0.9095290899276733, precision: 0.9206959653511106, recall: 0.9247141066170479, dice: 0.922700661478266, acc: 0.9206959657049514\n",
      "inference: 56.92841720581055, batch_iou: 0.8842397332191467, precision: 0.8859798367145021, recall: 0.8531283569651811, dice: 0.8692438171637579, acc: 0.8859798372398812\n",
      "inference: 56.80192184448242, batch_iou: 0.9147889614105225, precision: 0.8947713630750305, recall: 0.9557713021093065, dice: 0.924265953823474, acc: 0.8947713633846459\n",
      "inference: 56.87433624267578, batch_iou: 0.9095028638839722, precision: 0.924906860845091, recall: 0.940764348462872, dice: 0.9327682133712218, acc: 0.9249068611262825\n",
      "inference: 56.832096099853516, batch_iou: 0.8951706886291504, precision: 0.9157649400367388, recall: 0.9040644258338407, dice: 0.9098770689408628, acc: 0.9157649404337161\n",
      "inference: 56.768287658691406, batch_iou: 0.8287353515625, precision: 0.8455615535560032, recall: 0.7147457119895366, dice: 0.7746698460024857, acc: 0.8455615542805576\n",
      "inference: 56.78636932373047, batch_iou: 0.8887212872505188, precision: 0.8632744585918898, recall: 0.8809689694947075, dice: 0.8720319628527126, acc: 0.8632744590995627\n",
      "inference: 56.81071853637695, batch_iou: 0.8592876195907593, precision: 0.9116281145640069, recall: 0.8819956758896486, dice: 0.8965671166099674, acc: 0.9116281149607296\n",
      "inference: 56.823936462402344, batch_iou: 0.8264076709747314, precision: 0.6983150591118239, recall: 0.8753642665204866, dice: 0.7768800663515405, acc: 0.698315059562277\n",
      "inference: 56.758846282958984, batch_iou: 0.7913623452186584, precision: 0.5862518150164138, recall: 0.8420626839569982, dice: 0.6912494091401318, acc: 0.5862518154067675\n",
      "inference: 56.79804611206055, batch_iou: 0.8479745388031006, precision: 0.8503713069973183, recall: 0.7798655823190257, dice: 0.8135938020011428, acc: 0.8503713075606887\n",
      "inference: 56.78927993774414, batch_iou: 0.8680644035339355, precision: 0.8068423293142933, recall: 0.8936316879346216, dice: 0.8480222164859376, acc: 0.8068423299101398\n",
      "inference: 56.95868682861328, batch_iou: 0.8736013770103455, precision: 0.8339785467121443, recall: 0.8722197633802342, dice: 0.852670602630548, acc: 0.8339785472392904\n",
      "inference: 56.92559814453125, batch_iou: 0.9381079077720642, precision: 0.946101620285258, recall: 0.9497945811942679, dice: 0.9479445040284916, acc: 0.9461016204976495\n",
      "inference: 56.757598876953125, batch_iou: 0.9016040563583374, precision: 0.9122401482992124, recall: 0.9220205699924562, dice: 0.9171042841433736, acc: 0.9122401486393019\n",
      "inference: 56.835777282714844, batch_iou: 0.8479318618774414, precision: 0.6779247754393694, recall: 0.8627074769303981, dice: 0.759234751310783, acc: 0.6779247759174457\n",
      "inference: 56.84979248046875, batch_iou: 0.8934042453765869, precision: 0.8562479318390537, recall: 0.9066626215351669, dice: 0.8807344116822813, acc: 0.8562479322824338\n",
      "inference: 56.864479064941406, batch_iou: 0.8775070309638977, precision: 0.8794516284295738, recall: 0.929672456158231, dice: 0.9038649835318399, acc: 0.8794516286848731\n",
      "inference: 56.85551834106445, batch_iou: 0.8191719055175781, precision: 0.5835110383617444, recall: 0.8803224408633782, dice: 0.7018255406443442, acc: 0.583511038700099\n",
      "inference: 56.73164749145508, batch_iou: 0.8367985486984253, precision: 0.8113131703687217, recall: 0.8097771089074502, dice: 0.8105444118053811, acc: 0.8113131711096991\n",
      "inference: 56.78799819946289, batch_iou: 0.8048056364059448, precision: 0.6937446342383388, recall: 0.8149993521953091, dice: 0.74949949430168, acc: 0.6937446346587346\n",
      "inference: 56.7836799621582, batch_iou: 0.9232074618339539, precision: 0.9140308203923938, recall: 0.9279635552745525, dice: 0.9209444946337286, acc: 0.9140308207277662\n",
      "inference: 56.832096099853516, batch_iou: 0.8690453767776489, precision: 0.8723872886597829, recall: 0.8391684218597849, dice: 0.8554554896696424, acc: 0.8723872894577075\n",
      "inference: 56.76291275024414, batch_iou: 0.815811038017273, precision: 0.8187337576700803, recall: 0.7471461743302593, dice: 0.7813035754032917, acc: 0.8187337584334432\n",
      "inference: 56.83184051513672, batch_iou: 0.8725634813308716, precision: 0.9211581106352856, recall: 0.9028843726132391, dice: 0.9119297060423471, acc: 0.9211581110927881\n",
      "inference: 56.73990249633789, batch_iou: 0.8582034707069397, precision: 0.8519978540260493, recall: 0.9108258431211557, dice: 0.8804302607910311, acc: 0.8519978544442742\n",
      "inference: 56.835487365722656, batch_iou: 0.8930458426475525, precision: 0.9196492026422819, recall: 0.9466547742535277, dice: 0.9329566020181137, acc: 0.9196492029599853\n",
      "inference: 56.80137634277344, batch_iou: 0.8418670892715454, precision: 0.7799146701125821, recall: 0.871537622612956, dice: 0.8231845150465295, acc: 0.7799146708819833\n",
      "inference: 56.78473663330078, batch_iou: 0.8288342356681824, precision: 0.7658639945271234, recall: 0.8228056801293075, dice: 0.7933143747878804, acc: 0.7658639950330587\n",
      "inference: 56.717472076416016, batch_iou: 0.9112106561660767, precision: 0.8913034821717406, recall: 0.9044124764242838, dice: 0.8978101304480299, acc: 0.8913034829274051\n",
      "inference: 56.80976104736328, batch_iou: 0.7835826277732849, precision: 0.668703372327971, recall: 0.6868033465816458, dice: 0.6776325155563225, acc: 0.6687033728787072\n",
      "inference: 56.778560638427734, batch_iou: 0.9164618849754333, precision: 0.9089356604055335, recall: 0.94192910224985, dice: 0.9251383114203364, acc: 0.9089356607524594\n",
      "inference: 56.7786865234375, batch_iou: 0.8764607906341553, precision: 0.8557994275142601, recall: 0.9323199055076343, dice: 0.8924223642456427, acc: 0.8557994280127748\n",
      "inference: 56.867454528808594, batch_iou: 0.8918724656105042, precision: 0.9004304979033516, recall: 0.9297558476326815, dice: 0.9148582305173415, acc: 0.9004304982537052\n",
      "inference: 56.82476806640625, batch_iou: 0.9106041193008423, precision: 0.9295554118740585, recall: 0.8801338718608566, dice: 0.9041698053843292, acc: 0.9295554123496446\n",
      "inference: 56.778079986572266, batch_iou: 0.9302284121513367, precision: 0.9369521275987474, recall: 0.9390565930766344, dice: 0.9380031799565621, acc: 0.9369521278854943\n",
      "inference: 56.70441436767578, batch_iou: 0.7886170744895935, precision: 0.70331316596122, recall: 0.7423054953416223, dice: 0.7222834651030436, acc: 0.7033131665576301\n",
      "inference: 56.84940719604492, batch_iou: 0.8141337633132935, precision: 0.771278865002122, recall: 0.7577748295056771, dice: 0.7644672158228569, acc: 0.7712788657479875\n",
      "inference: 56.812416076660156, batch_iou: 0.9089797735214233, precision: 0.9231121984858347, recall: 0.8885980836552595, dice: 0.9055263842549238, acc: 0.9231121989467879\n",
      "inference: 56.786495208740234, batch_iou: 0.8356475830078125, precision: 0.6438904064322866, recall: 0.885839030836937, dice: 0.7457308980898885, acc: 0.6438904067439916\n",
      "inference: 56.86307144165039, batch_iou: 0.8758641481399536, precision: 0.8849590549575488, recall: 0.8535014427973354, dice: 0.8689456345523682, acc: 0.8849590555890968\n",
      "inference: 56.787841796875, batch_iou: 0.9332762956619263, precision: 0.947512716238116, recall: 0.9432756865801133, dice: 0.9453894540626752, acc: 0.9475127165587279\n",
      "inference: 56.72796630859375, batch_iou: 0.8769845366477966, precision: 0.84548811149019, recall: 0.9210752176630629, dice: 0.8816645669539888, acc: 0.8454881118781837\n",
      "inference: 56.78403091430664, batch_iou: 0.8417684435844421, precision: 0.8734501611422502, recall: 0.7964143253558204, dice: 0.8331552965910055, acc: 0.8734501619375491\n",
      "inference: 56.86812973022461, batch_iou: 0.8477968573570251, precision: 0.8175844588556546, recall: 0.8691248718622236, dice: 0.8425672106849657, acc: 0.8175844592121652\n",
      "inference: 56.77827072143555, batch_iou: 0.8921290636062622, precision: 0.9104380737969204, recall: 0.896443011271314, dice: 0.9033863436497427, acc: 0.9104380743378737\n",
      "inference: 56.760353088378906, batch_iou: 0.8313363790512085, precision: 0.7974269939499684, recall: 0.7931225841066779, dice: 0.7952689645480855, acc: 0.7974269946990619\n",
      "inference: 56.919776916503906, batch_iou: 0.8929712176322937, precision: 0.856735707134129, recall: 0.8814816373156347, dice: 0.8689325258891073, acc: 0.8567357077698631\n",
      "inference: 56.7657585144043, batch_iou: 0.9353737235069275, precision: 0.9211031817011643, recall: 0.9472992383352108, dice: 0.9340175682560238, acc: 0.9211031820144536\n",
      "inference: 56.84291076660156, batch_iou: 0.8129628300666809, precision: 0.7472532348218783, recall: 0.8165373287822402, dice: 0.7803604579937522, acc: 0.747253235447998\n",
      "inference: 56.76063919067383, batch_iou: 0.929463267326355, precision: 0.9185715624286517, recall: 0.9342456318571233, dice: 0.9263422990452079, acc: 0.9185715628171579\n",
      "inference: 56.76278305053711, batch_iou: 0.885498046875, precision: 0.8964592892557414, recall: 0.9130734041746191, dice: 0.9046900759458746, acc: 0.8964592897022221\n",
      "inference: 56.73030471801758, batch_iou: 0.9146682024002075, precision: 0.9018331145018681, recall: 0.9304589527183816, dice: 0.9159224233312964, acc: 0.9018331148851391\n",
      "inference: 56.841217041015625, batch_iou: 0.8961024284362793, precision: 0.8691340938574007, recall: 0.8847129538291958, dice: 0.8768543327968985, acc: 0.8691340944432989\n",
      "inference: 56.779903411865234, batch_iou: 0.8834008574485779, precision: 0.9345132042810154, recall: 0.9121449307545295, dice: 0.9231935958459951, acc: 0.934513204740898\n",
      "inference: 56.77657699584961, batch_iou: 0.8885068893432617, precision: 0.883169641668381, recall: 0.8975008649028287, dice: 0.8902775828592144, acc: 0.8831696420959664\n",
      "inference: 56.79865646362305, batch_iou: 0.8586373925209045, precision: 0.8248148684069018, recall: 0.8370926160325209, dice: 0.8309083897352529, acc: 0.8248148689312353\n",
      "inference: 56.79302215576172, batch_iou: 0.8146159648895264, precision: 0.7697053697017826, recall: 0.7519543941854508, dice: 0.7607263445305869, acc: 0.7697053703416553\n",
      "inference: 56.80934524536133, batch_iou: 0.8498205542564392, precision: 0.853043615652733, recall: 0.8175678255759699, dice: 0.8349290525736376, acc: 0.8530436162695016\n",
      "inference: 16.757919311523438, batch_iou: 0.21306104958057404, precision: 0.8710361867780418, recall: 0.770929660849417, dice: 0.8179313019505, acc: 0.8710361905792846\n",
      "MEAN inference: 56.60277509689331, batch_iou: 0.8663958311080933, precision: 0.8459188223129863, recall: 0.8736673369059867, dice: 0.8578825849645517, acc: 0.8459188228339278\n"
     ]
    }
   ],
   "source": [
    "model.train(False)\n",
    "model.to(device)\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "jaccard = JaccardIndex(num_classes=2)\n",
    "mIoU = 0\n",
    "Precision = 0\n",
    "Recall = 0 \n",
    "Dice = 0\n",
    "Pixel_accuracy = 0 \n",
    "time = 0\n",
    "metric_calculator = metrics.SegmentationMetrics(average=True, ignore_background=True, activation=\"softmax\")\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        tinputs, tlabels = data\n",
    "        tinputs = torch.tensor(tinputs).permute(0,3,1,2).to(device=device, dtype=torch.float)\n",
    "        tlabels = torch.tensor(tlabels).to(device=device, dtype=torch.long)\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        starter.record()\n",
    "        toutputs = model(tinputs)\n",
    "        ender.record()\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        batch_iou = 0\n",
    "        for i in range(len(toutputs)):\n",
    "            pred = F.softmax(toutputs, dim=1)[i].permute(1,2,0)[:,:, 1]\n",
    "            batch_iou += jaccard(pred.cpu(), tlabels[i].cpu().int())\n",
    "        mIoU += batch_iou/batch_size\n",
    "        time += curr_time\n",
    "        pixel_accuracy, dice, precision, recall = metric_calculator(tlabels.int(), toutputs)\n",
    "        Pixel_accuracy += pixel_accuracy\n",
    "        Dice += dice\n",
    "        Recall += recall\n",
    "        Precision += precision\n",
    "        print(\"inference: {0}, batch_iou: {1}, precision: {2}, recall: {3}, dice: {4}, acc: {5}\".format(curr_time, batch_iou/batch_size, precision, recall, dice, pixel_accuracy))\n",
    "mIoU /= len(test_loader)\n",
    "mTime = time / len(test_loader)\n",
    "Precision /= len(test_loader)\n",
    "Dice /= len(test_loader)\n",
    "Recall /= len(test_loader)\n",
    "Pixel_accuracy /= len(test_loader)\n",
    "# print(\"mean inference: {0}, mean iou: {1}\".format( mTime, mIoU))\n",
    "print(\"MEAN inference: {0}, batch_iou: {1}, precision: {2}, recall: {3}, dice: {4}, acc: {5}\".format(mTime, mIoU, Precision, Recall, Dice, Pixel_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
